---
title: "kotzeb0912 Telemetry Data"
subtitle: "Get Data from Wildlife Computers Data Portal"
draft: true
author:
- name: Josh M. London
  affiliation: 1
address:
- code: 1
  address: Alaska Fisheries Science Center, NOAA Fisheries, Seattle, Washington, USA
  email: josh.london@noaa.gov
  orcid: orcid.org/0000-0000-0000-0000
date: '`r Sys.Date()`'
disclaimer: >
  The scientific results and conclusions, as well as any views or opinions 
  expressed herein, are those of the author(s) and do not necessarily reflect 
  those of NOAA or the Department of Commerce.
abstract: >
  Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nullam nunc enim, accumsan vel ante a, faucibus convallis lorem. Quisque sit amet tellus molestie, eleifend justo eu, dapibus diam. Suspendisse suscipit neque id sapien semper fermentum ac nec dui. Maecenas porttitor ligula ligula, a laoreet ex congue sed. Mauris in egestas elit. Curabitur ut tellus vel lacus maximus elementum. Cras et bibendum libero, nec pellentesque risus. Integer suscipit sodales nulla, ullamcorper faucibus erat aliquet et. Donec condimentum nisl at enim gravida consectetur. Sed luctus eleifend lorem, quis tempor nisi lacinia at. Quisque sodales semper orci, eu aliquam enim sagittis eget.
output:
  bookdown::gitbook:
    self_contained: TRUE
    split_by: none
    config:
      toc:
        collapse: subsection
        scroll_highlight: yes
        before: null
        after: null
      toolbar:
        position: static
params:
   get_data: FALSE
---

# Connect to Wildlife Computers Data Portal

Wildlife Computers (Redmond, Washington, USA) provides an API for their data
portal that allows us to download the latest telemetry data for any deployment. 
To facilitate connection and use of this API within R, the `wcUtils` package
has been developed.

The data portal is not a public repository. Data access is controlled by the
data owner. Thus, only those users who are either owners of the deployment 
data or users who have been granted access by the owner can access the API.

The `wcUtils` package is available for install from GitHub:

```{r install-wcutils}
if (!require('devtools')) install.packages('devtools')
if (!require('wcUtils')) {
  devtools::install_github('jmlondon/wcUtils')
}
if (!require('tidyverse')) install.packages('tidyverse')
```


# Download `kotzeb0912` Telemetry

All of the deployments have been labeled within the data portal as *ProjectID = KotzEB09*. We will use that information to only download the relevant data.

```{r get-data-from-wc, eval = as.logical(params$get_data)}
# first thing, get deployment data from WCDP
r <- wcUtils::wcPOST()
# get KotzEB09 ids and download the data
aleut_ids <- wcUtils::wcGetProjectIDs(r,project = 'KotzEB09')

for (i in 1:length(aleut_ids)) {
  zipfile <- wcUtils::wcGetZip(id = aleut_ids[i])
  file.copy(zipfile,'.',overwrite = TRUE)
  file.rename(file.path(basename(zipfile)),
              file.path(paste(aleut_ids[i],"zip",sep = '.'))
  )
}
```

The zip files downloaded from the data portal are named based on the 
unique id assigned within the data portal. For our deployments, we have 
assigned each a unique `DeployID`. It would be more informative if we could
rename all of these zip files to the assigned `DeployID`. Eventually, this
functionality could be implemented within the `wcUtils` package and the API,
but for now, we'll just open each zip file and examine the data files to
extract the assigned `DeployID`.

```{r rename-zip-files, eval = as.logical(params$get_data)}
for (zipfile in list.files(pattern = ".zip",full.names = TRUE)) {
  summary_name <- grep('*-Summary.csv',
                      unzip(file.path(
                                      basename(zipfile)),
                            list = TRUE)$Name,
                       value = TRUE)
  deployid <- read.csv(unzip(zipfile, files = summary_name))$DeployID
  deployid <- as.character(deployid)
  file.remove(summary_name)
  file.rename(file.path(zipfile),
              file.path(paste(deployid,"zip",sep = '.'))
  )
}
```

## List of Archive Files

```{r list-downloaded-files}
tibble(file_name = (list.files(pattern = ".zip"))) %>% knitr::kable()
```

# Create datapack

Now that we have our files downloaded and stored locally, we want to create a
datapack for upload to DataONE. The process described here borrows heavily from
the [vignette provided DataONE](https://cran.r-project.org/web/packages/dataone/vignettes/upload-data.html) in the `dataone` package.

First, we load the required libraries and then create an empty DataPackage.

```{r create-datapack}
if(!require('dataone')) install.packages('dataone')
if(!require('datapack')) install.packages('datapack')
if(!require('uuid')) install.packages('uuid')

dp <- new("DataPackage")
```

```{r add-files-datapack}
metadataObj <- new("DataObject", 
                   format = "https://www.iso.org/standard/53798.html",
                   filename = "kotzeb0912_raw_iso19115.xml")
dp <- addMember(dp, metadataObj)

for (zipfile in list.files(pattern = ".zip")) {
 sourceObj <- new("DataObject",format = "application/zip",filename = zipfile)
 dp <- addMember(dp, sourceObj, metadataObj)
}

progObj <- new("DataObject", format = "application/R", 
               filename = "00_kotzeb0912_get_data.Rmd", 
               mediaType = "text/x-rsrc")
dp <- addMember(dp, progObj, mo = metadataObj)

outputObj <- new("DataObject", format="text/html", 
                 filename="00_kotzeb0912_get_data.html") 
dp <- addMember(dp, outputObj, mo = metadataObj)

```

# Establish Connection with DataONE Node

# Send datapack to DataONE Node
